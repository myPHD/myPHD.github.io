---

layout: post

title: "ISL-chap2 : Statistical Learning"

---

## 1 통계학습이란?
- 용어정리
 **Input**: predictors, independent variables, features, variables
 **Output**: response, dependent variables

- 통계모델을 다음과 같이 정의하자
 
 $$Y=f(X)+\epsilon$$

 - $$$\epsilon$$$은 radom error term이며 평균이 0
 - 우리의 목표는 $$$f$$$를 예측하는 것

### 1-1. $$$f$$$ 함수를 예측하는 이유
#### Prediction
- 새로운 변수 $$$X$$$에 대해서 그에 따른 $$$Y$$$값 예측이 목표
- error term은 0으로 수렴하기 때문에 $$$Y$$$값을 다음과 같이 예측가능
 
 $$\hat{Y}=\hat{f}(X)$$
 - $$$\hat{f}$$$는 **black box**(미지의 것)로 여겨짐. 정확한 형태의 $$$\hat{f}$$$의형태와 관련이 없기 때문
 
- $$$\hat{Y}$$$의 예측정확도는 아래 두개의 항들과 관련있음
 - 오차의 제곱 평균을 다음과 같이 정의할 때

$$E(Y-\hat{Y})^2=E(f(x)+\epsilon-\hat{f(X)})$$
$$=[f(X)-\hat{f}(X)]^2 + Var(\epsilon)$$
 - 첫 항을 **reducible error**, 둘째항을 **irreducible error** 라 한다.
- 그래서 우리의 목표는 **reducible error**를 줄이는 쪽으로 진행하게 된다.

#### Inference
 - $$$Y$$$의 예측이 아닌 $$$X$$$와 $$$Y$$$의 관계를 밝혀내는 것이 목표
 - **추론(Inference)**과정에서 기초적인 4가지 질문
  1) 어떤 X가 Y와 관련이 있는가
  2) X와 Y간에 어떠한 관련이 있는가
  3) 그 관계가 선형으로 설명이 되는가? 더 복잡한가

 - 정확도 vs 편리성 의 선택에 따라서 X와 Y의 관계를 다르게 설명할 수 있다
  - 편리성을 더 따질 때는 선형모델이 더 좋을 수 있음
  - 정확도를 따질 때는 보다 복잡한 모델이 좋을 수 있음

### 1-2. $$$f$$$함수를 어떻게 예측하는가
- 예측방법은 두가지로 나눔 **parametric**과 **non-parametric**

#### parmetric Methods
- 두단계로 되어 있음
1) 함수 형태에 대한 가정하기(모델 설정하기)
2) training data를 통해서 model을 fit 또는 train하기
 - 모델을 fit 혹은 train하는 방식으로 **least square** 방식이 제일 많이 이용됨
- 단점
 - 모델이 실제 함수$$$f$$$와 안맞으면 성능이 안 좋을 수 있음
   - 이 문제를 **flexible model**을 통해서 해결하나 이를 위해서는 더 많은 **parameter**를 구하는 과정이 필요함. 그리고 **overiftting**(과적합)이 발생할수 있음

####Non-parametric Methods
- 근처에 데이터 점에 대한 정보를 이용하여 함수 $$$f$$$을 결정한다
- 모델을 설정하지 않아도 되기 때문에 **parametric method**의 단점이 해결됨
- 주변 데이터점의 몇개를 선택하느냐에 따라서 **smoothness**가 변함
- 단점
 - $$$f$$$함수를 예측하기 위해서 **parametric method**보다 훨신 더많은 양의 예측 결과가 필요함
 - 적은 개수의 주변 데이터 점을 선택하면 과적합이 발생할 수 있음=> 적절한 **smoothness**선택이 필요함

### 1-3. 예측정확도와 해석가능성 간의 관계( Prediction Accuracy vs Model Interpretability )
 - **Restrictive Models** : 모델이 restrictive 할수록 interpretable 하기 좋음, Accuracy는 낮을 수 있음
 - **flexible Models** : 모델이 flexible 할수록 interpretable 하기는 어려우나, Accuracy는 더 좋을 수 있음
  - 그러나 너무 flexible하면 overfitting(과적합)발생가능
 - Flexibility : Subset selection, Lasso < Least Squares < Generalized additive Models, Trees < SVM < Bagging, Boosting
 

### 1-4. 지도학습과 비지도학습( Supervised vs Unsupervised Learning)
- **Supervised Learning** 은 output이 있으나 **Unsupervised Learning**은 otuput이 없음
- **Unsupervised learning**은 데이터들이 서로 섞이지 않고 끼리끼리 뭉쳐져 있을 때의 분석에 적합함 (**cluster analysis**)
- **Semi-supervised learning**은 몇개의 데이터는 output이 있고 몇개의 데이터는 output이 없을 때 적합함

### 1-5. 회귀와 분류(Regression vs Classification Problems)
- 1단원에서 앞서 설명했듯이 Regression은 quantative 한 output, Classification은 qualitative한 output에서 쓰인다.
- Input이 quantitative인지 qualitative인지는 중요하지 않다(뒷 단원에서 알게 됨)

## 2. 모델 정확도 평가방법
 - **There is no free lunch in statistics** - 모든 상황에 잘 맞는 완벽한 모델은 없음
 - 상황(데이터)에 따라 잘 맞는 모델을 선ㅌ낵해야됨

### 2-1. 모델이 잘 맞는지를 측정하는 방법
 - **MSE** : mean square error로 판별
 $$MSE=\frac{1}{n}\sum_{i=1}^{n}{(y-\hat{f}(x))^2}$$
 - **주의** : 우리의 목적은 training data의 정보를 통해서 test data에 모델이 잘 맞는지 보는거임
   - Training data의 MSE를 마구 줄인다고 해서 test data의 accuracy가 높아지는 것이 아님 너무 과하면 overfitting(과적합) 발생
 - 적절한 정도의 flexibility를 정하는 것이 좋음(flexibility를 degree of freedom(자유도)라고도 함)
 - 데이터 수가 적으면 **cross validation**을 사용해서 MSE를 측정함

### 2-2 편향 vs 분산 (Bias vs Variance Tradeoff)
 - 이전에는 모델에 편향와 분산에 대해서 다뤄봤고 이번에는 새로운 데이터에 대한 편향과 분산에 대해 다룸
 - 새로운 데이터의 제곱평균(MSE)은 다음과 같이 정의 가능
 $$$E(y_0-\hat{f}(x_0))^2=Var(\hat{f(x_0)})+[Bias(\hat{f(x_0)})]^2+Var(\epsilon) $$$
  - 순서대로 **variance, bias, irreducible error** 라고 표현함
  - 이전에 배운 **reducible error**항을 variance와 bias로 나눈 것임
  - **Variance** : 새로운 데이터를 사용했을 때 얼마나  $$$\hat{f}$$$ 값이 변하는지
   (모든 데이터들에 대한 $$$\hat{f}$$$값의 평균과 이 데이터의$$$\hat{f}$$$값의 제곱차)
  - **Bias** : $$$f$$$값과 $$$\hat{f}$$$값의 차이가 얼마나 나는지
  (모든 데이터의 $$$\hat{f}$$$값과 실제 $$$f$$$값 사이의 차이의 평균)
 - 모델이 더 flexible할수록 bias가 작고 variance가 크다
 - MSE를 최소화하기 위해서는 flexibility를 변화시켜줘야 하고 그럴때마다 bias와 variance는 반대로 움직인다

### 2-3 분류의 경우에는?(Classification)
 - error rate를 다음과 같이 생각 가능
  $$$\frac{1}{n}\sum_{i=1}^{n}{I(y_i\neq y_i)}$$$
 
 - Test sample에 대해서 나타내면 
  $$$Ave(I(y_0\neq y_0))$$$
 - test sample의 error rate를 가장 감소시키는 것이 목표 

#### Bayes Classifier
 - test error를 최소화 하기 위해 확률 값이 가장 높은 곳에 분류를 하도록 도와줄 classifier를 도입할 것임.
  $$Pr(Y=j|X=x_0)$$
  - 이렇게 에러를 최소화 하기 위해 도입한 classifier를 **Bayes Classifier**라고 함
  - 보통 $$$Pr(Y=j|X=x_0)>0.5$$$ 로 잡을 것임
  
 - 이렇게 만들어진 class의 경계면을 **Bayes decision boundary**라고 함
 - Bayes classifier가 만들어낸 가장 최소의 error를 **Bayes error rate** 라고 함
   (**Bayes error rate**는 **irreducible error**과도 유사점이 많다)
  이는 다음과 같이 나타낼 수 있음
  $$1-E(\max_{j}{Pr(Y=j|X)})$$
  
#### K-nearest Neighbors(KNN)
 - **Bayes classifier**를 통해서 분류를 하면 좋겠지만 우리는 $$$Pr(Y=j|X=x_0)$$$ 값을 모름
 - 그래서 Conditional property가 아닌 conditional property의 예측값을 넣어야 됨!
 - 그 방법중 하나가 **K-nearest neighbors classifier**이고 아래와 같이 정의함
 $$Pr(Y=j|X=x_0)=\frac{1}{K}\sum_{i\in{N_0}}^{ }{I(y_i= y_i)}$$
 - 그뒤 **KNN**은 **Bayes rule**(베이즈 분류)을 사용하여 최고의 확률을 가진 클래스로 test observation들을 분류함
 - 대체로 Optimal Bayes classifier와 상당히 가까운 결과를 뽑아냄
 - 주변 점의 개수인 **K** 값을 잘 지정해주어야 함
   - K가 작으면 너무 flexible 하여 overfitting이 될 수 있으며(low bias high varaince)
   - K 값이 너무 크면 선형에 가까워지며 underfitting 되어 부정확한 결과가 나올 수 있다
    (low variance high bias)
  

 ####즉 regression이든 classification이든 적절한 flexibility를 정하는 것이 통계학습을 하는데 중요하다는 것이다#####
 